---
title: Análisis exploratorio de un conjunto de datos de indicadores urbanos
author:
  - name: Rebeca Company
    affil: 1,*
  - name: Alejandro Dionis
    affil: 1,*
  - name: Gabriel Ivars
    affil: 1,*
  - name: Julio Garcia
    affil: 1,*
affiliation:
  - num: 1
    address: |
      Universitat de València -
      ETSE-UV, Avinguda de l'Universitat, 46100 Burjassot, Valencia
correspondence: |
  {recombar, adioros, gaia2, jugarbus\}\@alumni.uv.es
authorcitation: |
  Company, R.; Dionis-Ros, A.; Ivars, G.; Garcia, J.
  
# document options
journal: Universitat de València
type: article
abstract: |
  El presente artículo es un proyecto de la Asignatura Análisis Exploratorio de Datos, en el que se realiza un análisis exploratorio del conjunto de datos de Indicadores Urbanos, publicado por el Instituto Nacional de Estadística. A lo largo del mismo se plantean y responden preguntas de interés sobre aspectos demográficos, económicos y sociales de España en los últimos 15 años. 
# back matter
keywords: |
  Indicadores Urbanos; Tasa ; Población, Análisis Exploratorio
authorcontributions: |
    Todos los autores contribuyeron de manera equitativa a este trabajo.
dataavailability: |
  Los conjuntos de datos analizados en el presente artículo están disponibles en la sección "Indicadores Urbanos. Últimos datos." del repositorio público de conjuntos de datos abiertos del Instituto Nacional de Estadística INEbase
  \url{https://www.ine.es/dyngs/INEbase/listaoperaciones.htm}.
conflictsofinterest: |
  Los autores declaran no tener ningún conflicto de interés
abbreviations:
  - short: MDPI
    long: Multidisciplinary Digital Publishing Institute
  - short: INE
    long: Instituto Nacional de Estadística
endnotes: false
output: 
  rticles::mdpi_article:
    extra_dependencies: ["float"]
always_allow_html: true
header-includes:
  - \setlength{\parindent}{0pt} # Eliminar sangría
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning=FALSE, out.width = '100%', fig.align='left', message = FALSE, fig.pos = "H", out.extra = "")
```



# Introducción

Hablar de los 3 datasets y de donde se han obtenido. BLABLABLA



# Objetivos

El objetivo principal de este trabajo es llevar a cabo un análisis exploratorio de los conjuntos de datos seleccionados, con el fin de identificar posibles anomalías y comprender los aspectos más relevantes de la información contenida. Este análisis servirá como base para futuros estudios o para la aplicación de métodos más avanzados.

Asimismo, se busca responder a las siguientes preguntas clave a partir de los datos analizados:

* ¿Reflejan los datos algunos de los eventos más significativos en España, como la crisis económica de 2008-2014 o la pandemia de COVID-19 en 2019?

* ¿Qué podemos deducir sobre la situación demográfica de España a partir de estos datos?

# Análisis exploratorio de los datos



## Importación de los datos

```{r, include=FALSE}
rm(list = ls())
pacman::p_load(readr, tidyverse, ggplot2, dplyr, plotly, lubridate, visdat, ggpubr, knitr, mice, DataExplorer, naniar, kableExtra, corrplot, GGally, gridExtra) # verifica si los paquetes están instalados y, si no lo están, los instala y luego los carga
```


```{r, include=FALSE}
getOption("encoding")
guess_encoding("./data/demograficos.csv")
guess_encoding("./data/economicos.csv")
guess_encoding("./data/sociales.csv")
#El encoding es de UTF-8 en los 3 ficheros de datos
```


```{r, include=FALSE}
dem <- read_delim("./data/demograficos.csv", delim = ";", escape_double = FALSE, locale = locale(decimal_mark = ",", grouping_mark = "."), trim_ws = TRUE, show_col_types = FALSE)

eco <- read_delim("./data/economicos.csv", delim = ";", escape_double = FALSE, locale = locale(decimal_mark = ",", grouping_mark = "."), trim_ws = TRUE, show_col_types = FALSE)

soc <- read_delim("./data/sociales.csv", delim = ";", escape_double = FALSE, locale = locale(decimal_mark = ",", grouping_mark = "."), trim_ws = TRUE, show_col_types = FALSE)
```




```{r, include=FALSE}
#La variable Total del dataset social es de tipo character cuando debería ser numérica.
soc <- soc %>%
  mutate(Total = str_replace_all(Total, "\\.", "")) %>%  # Eliminar separadores de miles
  mutate(Total = str_replace_all(Total, ",", ".")) %>%   # Cambiar comas por puntos
  mutate(Total = as.numeric(Total))                      # Transformar a tipo numérico
```


```{r, include=FALSE}
#Al modificar el tipo de la variable Total se aprecia un aumento del número de valores faltantes. Exploremos los posibles motivos. 

df_ori <- read_delim("./data/sociales.csv", delim = ";", escape_double = FALSE, locale = locale(decimal_mark = ",", grouping_mark = "."), trim_ws = TRUE)

na_diff <- which(!is.na(df_ori$Total) & is.na(soc$Total))
diff_observations <- df_ori[na_diff, , drop = FALSE]
diff_observations

# Hay 1461 observaciones en el dataframe social con un valor de ".." en la variable Total
```



```{r, include=FALSE}
# Transformar variable Periodo a tipo fecha

dem_2 <- dem %>%
  mutate(Periodo = ymd(paste0(Periodo, "-01-01")))

eco_2 <- eco %>%
  mutate(Periodo = ymd(paste0(Periodo, "-01-01")))

soc_2 <- soc %>%
  mutate(Periodo = ymd(paste0(Periodo, "-01-01")))
```



```{r, include=FALSE}
# Los datos faltantes en la variable Municipios son los valores asociados a Total Nacional. Por lo que se va a eliminar la columna Total Nacional y se van a rellenar los NA con el Valor "Total Nacional".
# También se modifica la variable sexo para que sea de tipo factor.

DEM<- dem_2 %>% replace_na(list(Municipios = "Total Nacional")) %>% select(-"Total Nacional") %>%  mutate(
                    Sexo = as.factor(Sexo))
ECO<- eco_2 %>% replace_na(list(Municipios = "Total Nacional")) %>% select(-"Total Nacional") %>%  mutate(
                    Sexo = as.factor(Sexo))
SOC<- soc_2 %>% replace_na(list(Municipios = "Total Nacional")) %>% select(-"Total Nacional") %>%  mutate(
                    Sexo = as.factor(Sexo))
```




```{r, include=FALSE}
# Se concatenan los 3 datasets ya que tienen formato tidy y no hay coincidencias en la variable 'Indicadores', que es común a todos los dataframes.
full_df <- bind_rows(DEM, ECO, SOC)
```




```{r, include=FALSE}
# Datos juntos sin sexo solamente

total_df_nosex <- full_df %>% filter(Sexo=='Total') %>% select(-Sexo) 
```




Antes de importar, primero se verificó que la codificación de los tres datasets fuera la misma, confirmando que todos estaban en formato UTF-8. Una vez comprobado, a la hora de importar los datasets, fue necesario establecer el delimitador de campos con el punto y coma (;) y adaptar el formato original al de R, ya que en los datasets el decimal_mark es la coma (,) y el grouping_mark es el punto (.). Las variables a estudiar, las cuales son coincidentes en los tres datasets, son:


- *Total Nacional* : Variable redundante con un único valor "Total Nacional", que toma verdadero valor cuando el atributo *Municipios* es vacío. 

- *Municipios* : Municipio del que se han obtenido los datos.

- *Indicadores* : Tipo de estadístico demográfico, económico o social que se está calculando en cada observación. Se comentarán más a fondo en los hallazgos obtenidos, ya que se trata de un elevado número de indicadores (35 niveles).

- *Sexo* : Sexo del cual se está obteniendo el indicador estadístico (hombre o mujer).

- *Periodo* : Año al que hace referencia el indicador estadístico.

- *Total* : Valor numérico asociado al indicador estadístico, que puede ser un valor absoluto, una tasa o un porcentaje, dependiendo del tipo de estadístico.



Otras consideraciones que se tuvieron en cuenta fueron que la variable *Total* del dataset social era de tipo "character" y se transformó a tipo "numeric" para poder realizar operaciones. Esto se debe a que esta columna contenía valores "..", que serán considerados como faltantes en nuestro análisis. Al importar estos valores, R determinó que la clase de esta variable era de tipo "character". Además, se transformó la variable *Periodo* a tipo "Date" y la variable *Sexo* a "factor".


Posteriormente se concatenaron los tres datasets ya que estaban en formato "tidy". y finalmente, el dataset se separó en cuatro partes:

- Datos totales nacionales con *Sexo* = "Total".

- Datos totales nacionales por sexo.

- Datos por municipios con *Sexo* = "Total".

- Datos por municipios y sexo.



Esto se hizo porque no tenía sentido estudiar los datos de forma conjunta, ya que muchos de los indicadores tienen distintas escalas. No obstante, también se ha guardado el dataset completo ya que es necesario para el estudio de los datos faltantes.




## Análisis de datos faltantes


```{r, include=FALSE}
# Comprobar filas duplicadas
duplicated_rows <- full_df %>%
  filter(duplicated(full_df))

# Ver las filas duplicadas
print(duplicated_rows)

#No hay duplicados
```



En esta sección previa al análisis univariante y bivariante se realizó un análisis de la estructura de los faltantes y del dataset en general. Para asegurar que nuestro conjunto de datos sea coherente, se evaluó el porcentaje de valores faltantes (*NA*) presentes en cada variable:



```{r}
perc_total <- colSums(is.na(full_df)) / dim(full_df)[1] * 100
perc_total <- as.data.frame(perc_total)

# Cambiar el nombre de la columna
perc_total <- perc_total %>% rename(Porcentaje = perc_total) %>% mutate(Porcentaje = round(Porcentaje, 2))

kable(perc_total, caption = "Porcentajes de NAs\\label{total_na}")
```


Del dataset completo, únicamente se observan valores faltantes en la variable *Total*, siendo este un valor muy elevado (71.26%). 

Es importante señalar que durante la importación de los datasets, se eliminaron los datos faltantes en la variable Municipios que correspondían a los valores asociados a "Total Nacional". Por esta razón, se eliminó la columna Total Nacional y se rellenaron los valores *NAs* de *Municipios* con el valor "Total Nacional".

También se observó que al modificar el tipo de la variable *Total* se apreció un incremento del número de valores faltantes.  Esto se debió a las 1461 observaciones del dataframe social con un valor de ".." que al transformar a "numeric", R asoció dichos valores a valores faltantes.

Además, no se encontraron observaciones duplicadas a lo largo del dataset completo.

A continuación se van a estudiar estos valores faltantes en función del resto variables no numéricas.


#### Por *Sexo*


```{r include=FALSE}
g1 <- full_df %>% filter(Municipios=='Total Nacional') %>% 
  filter(is.na(Total)) %>%
  count(Sexo, sort = TRUE) %>%
  ggplot(aes(x = reorder(Sexo, n), y = n)) +
    geom_bar(stat = "identity", fill = "skyblue") +
    coord_flip() +  # Voltea el gráfico para que los indicadores estén en el eje y
    labs(
      title = "Conteo NAs por Sexo del dataset total nacional",
      x = "Sexo",
      y = "Cantidad de NA"
    ) +
    theme_minimal()

g2 <- full_df %>% filter(Municipios!='Total Nacional') %>% 
  filter(is.na(Total)) %>%
  count(Sexo, sort = TRUE) %>%
  ggplot(aes(x = reorder(Sexo, n), y = n)) +
    geom_bar(stat = "identity", fill = "skyblue") +
    coord_flip() +  # Voltea el gráfico para que los indicadores estén en el eje y
    labs(
      title = "Conteo NAs de por Sexo del dataset por municipios",
      x = "Sexo",
      y = "Cantidad de NA"
    ) +
    theme_minimal()



ggarrange(g1, g2, nrow = 2)

```

```{r}
#Porcentajes NAs de Sexo dataset Total Nacional
n_na_sex <- full_df %>% filter(Municipios=='Total Nacional') %>% 
  filter(is.na(Total)) %>%
  count(Sexo, sort = TRUE)

total_sex <- full_df %>% filter(Municipios=='Total Nacional') %>% 
  count(Sexo, sort = TRUE)

n_na_sex$Porcentaje <- round(n_na_sex$n / total_sex$n * 100, 2)
n_na_sex$Porcentaje_total <- round(n_na_sex$n / dim(full_df %>% filter(Municipios == 'Total Nacional'))[1] * 100, 2)
```




```{r}
kable(n_na_sex, caption = "Porcentajes de NAs por sexo en el dataset Total Nacional\\label{total_sex_na}")

```


```{r}
#Porcentaje NAs de Sexo dataset por municipios
n_na_sex_2 <- full_df %>% filter(Municipios!='Total Nacional') %>% 
  filter(is.na(Total)) %>%
  count(Sexo, sort = TRUE)

total_sex_2 <- full_df %>% filter(Municipios!='Total Nacional') %>% 
  count(Sexo, sort = TRUE)

n_na_sex_2$Porcentaje <- n_na_sex_2$n / total_sex_2$n * 100
n_na_sex_2$Porcentaje_total <- round(n_na_sex_2$n / dim(full_df %>% filter(Municipios!='Total Nacional'))[1] * 100,2 )

```

```{r}

kable(n_na_sex_2, caption = "Porcentajes de NAs por sexo en el dataset por municipios\\label{mun_sex_na}")

```




Como se observa en la Tabla \ref{total_sex_na} y Tabla \ref{mun_sex_na}, tanto para hombres como para mujeres, aproximadamente el 85% de sus observaciones tienen valores faltantes en la columna *Total*, lo que representa mas o menos el 28% del total de observaciones en ambos conjuntos de datos. Para el nivel Total (variable *Sexo*), en torno al 40% de sus observaciones tienen valores faltantes, representando el 14% aproximandamente del total de observaciones en ambos dataframes. Por tanto, debido al elevado porcentaje de valores faltantes en las observaciones desglosadas por sexo, se decidió no incluir en el análisis observaciones de hombres y mujeres por separado y optamos por trabajar únicamente con el total combinado de ambos sexos. Por tanto, a partir de esta decisión se continuó con el análisis de estos dos conjuntos de datos:

- Datos totales nacionales con *Sexo* = "Total".


- Datos por municipios con *Sexo* = "Total".




```{r}
# (total_df_nosex) Ahora solo se va a usar el dataset Sexo=Total 
```


#### Por *Indicadores*, *Periodo* y *Municipios*

```{r}
nombres_originales <- unique(total_df_nosex$Indicadores)

nombres_abreviados <- c("Pob_Res", "Pob_0_14", "Pob_15_64", "Pob_65mas", "Edad_Med", 
                       "Nac_Total", "Nat_Nac_Total", "Nac_Ext_Total", "Ext_Total", 
                       "Tasa_Natalidad", "Tasa_Mortalidad", "Esp_Vida", "Hijos_Mujer", 
                       "Tasa_Desempleo", "Ocup_20_64", "Tasa_Actividad", "Emp_Servicios", 
                       "Emp_Industria", "Renta_Hogar", "Renta_Hab", "Renta_UC", "Num_Hogares", 
                       "Tam_Hogar", "Hog_1P", "Viv_Catastro", "Viv_Censo", "Viv_Vacías", 
                       "Alq_m2_Anual", "Alq_Mensual", "Med_Alq_m2_Anual", "Med_Alq_Mensual", 
                       "Q1_Alq_m2_Anual", "Q1_Alq_Mensual", "Q3_Alq_m2_Anual", "Q3_Alq_Mensual")

# Abraviar los nombres de la variable Indicadores almacenandolos en la variable Ind
total_df_nosex <- total_df_nosex %>%
  mutate(Ind = recode(Indicadores, 
                     !!!setNames(nombres_abreviados, nombres_originales)))
```


```{r include=FALSE}
 g3 <- total_df_nosex %>% filter(Municipios=='Total Nacional') %>% 
  filter(is.na(Total)) %>%
  count(Ind, sort = TRUE) %>%
  ggplot(aes(x = reorder(Ind, n), y = n)) +
    geom_bar(stat = "identity", fill = "skyblue") +
    coord_flip() +  # Voltea el gráfico para que los indicadores estén en el eje y
    labs(
      title = "NAs por Indicadores del dataset total nacional",
      x = "Indicadores",
      y = "Cantidad de NA"
    ) +
    theme_minimal()

g4 <-  total_df_nosex %>% filter(Municipios!='Total Nacional') %>% 
  filter(is.na(Total)) %>%
  count(Ind, sort = TRUE) %>%
  ggplot(aes(x = reorder(Ind, n), y = n)) +
    geom_bar(stat = "identity", fill = "skyblue") +
    coord_flip() +  # Voltea el gráfico para que los indicadores estén en el eje y
    labs(
      title = "NAs por Indicadores del dataset total nacional",
      x = "Indicadores",
      y = "Cantidad de NA"
    ) +
    theme_minimal()

ggarrange(g3, g4, nrow = 2, heights = c(1, 1))


```





```{r}
# Obtenemos los porcentajes de valores faltantes dataset Total Nacional
na_ind_count <- total_df_nosex %>% 
  filter(Municipios == 'Total Nacional') %>% 
  filter(is.na(Total)) %>%
  count(Indicadores, sort = TRUE)

# Obtenemos el total de indicadores
total_ind <- total_df_nosex %>% 
  filter(Municipios == 'Total Nacional') %>% 
  count(Indicadores, sort = TRUE)

# Unimos ambos dataframes para que tengan el mismo número de filas
result <- total_ind %>%
  left_join(na_ind_count, by = "Indicadores", suffix = c("_total", "_na"))

# Reemplazamos los NA en la columna de conteo de valores faltantes por 0
result <- result %>%
  mutate(n_na = ifelse(is.na(n_na), 0, n_na))

# Calculamos el porcentaje de valores faltantes
result <- result %>%
  mutate(perc = (n_na / n_total) * 100) %>%
  arrange(desc(perc))

na_ind_list <- result[result$perc < 50,]


# Eliminamos los indicadores que tengan más de 50% de valores faltantes
clean_total_df <- total_df_nosex %>% filter(Municipios=='Total Nacional') %>% 
  filter(Indicadores %in% na_ind_list$Indicadores) %>%
  mutate(
    Indicadores = as.factor(Indicadores),
    Ind = as.factor(Ind)
  ) %>% select(-Municipios)

# Son 14 indicadores los que se eliminan
```



```{r}
# Obtenemos los porcentajes de valores faltantes dataset por municipios
na_ind_count_2 <- total_df_nosex %>% filter(Municipios!='Total Nacional') %>% 
  filter(is.na(Total)) %>%
  count(Indicadores, sort = TRUE)

total_ind_2 <- total_df_nosex %>% filter(Municipios!='Total Nacional') %>% 
  count(Indicadores, sort = TRUE) 

na_ind_count_2$perc <- na_ind_count_2$n / total_ind_2$n * 100

na_ind_list_2 <- na_ind_count_2[na_ind_count_2$perc < 50,]



# Eliminamos los indicadores que tengan más de 50% de valores faltantes
clean_mun_df <- total_df_nosex %>% filter(Municipios!='Total Nacional') %>% 
  filter(Indicadores %in% na_ind_list_2$Indicadores) %>%
  mutate(
    Municipios = as.factor(Municipios),
    Indicadores = as.factor(Indicadores),
    Ind = as.factor(Ind)
  )

#Son 15 indicadores los que se eliminan
```



En ambos conjuntos de datos, la distribución de los valores faltantes variaba entre los diferentes niveles de las variables, alejándose considerablemente de una distribución uniforme. Como criterio, se eliminaron aquellos niveles de variables que tenían más del 50% de valores faltantes relativo al número de observaciones de cada nivel.

Para el caso de la variable *Indicadores*, se eliminaron  14 y 15 indicadores del conjunto de datos nacional y del de municipios, respectivamente.


```{r include=FALSE}
 g5 <- clean_total_df %>%
  filter(is.na(Total)) %>%
  count(Periodo, sort = TRUE) %>%
  ggplot(aes(x = reorder(Periodo, n), y = n)) +
    geom_bar(stat = "identity", fill = "skyblue") +
    coord_flip() +  # Voltea el gráfico para que los indicadores estén en el eje y
    labs(
      title = "NAs por año del dataset total nacional",
      x = "Periodo",
      y = "Cantidad de NA"
    ) +
    theme_minimal()

g6 <- clean_mun_df %>%
  filter(is.na(Total)) %>%
  count(Periodo, sort = TRUE) %>%
  ggplot(aes(x = reorder(Periodo, n), y = n)) +
    geom_bar(stat = "identity", fill = "skyblue") +
    coord_flip() +  # Voltea el gráfico para que los indicadores estén en el eje y
    labs(
      title = "NAs por año del dataset por municipios",
      x = "Periodo",
      y = "Cantidad de NA"
    ) +
    theme_minimal()

ggarrange(g5, g6, nrow = 2, heights = c(1, 1.5))
```


```{r include=FALSE}
# Obtenemos los porcentajes de valores faltantes dataset Total Nacional
na_period_count <- clean_total_df %>%
  filter(is.na(Total)) %>%
  count(Periodo, sort = TRUE)

# Obtenemos el total de Periodos
total_period <- clean_total_df %>%
  count(Periodo, sort = TRUE)

# Unimos ambos dataframes para que tengan el mismo número de filas
result_period <- total_period %>%
  left_join(na_period_count, by = "Periodo", suffix = c("_total", "_na"))

# Reemplazamos los NA en la columna de conteo de valores faltantes por 0
result_period <- result_period %>%
  mutate(n_na = ifelse(is.na(n_na), 0, n_na))

# Calculamos el porcentaje de valores faltantes
result_period <- result_period %>%
  mutate(perc = (n_na / n_total) * 100) %>% 
  mutate(perc_total = (n_na / dim(clean_total_df)[1]) * 100) %>%
  arrange(desc(perc))

print(head(result_period, 5))
```


```{r include=FALSE}
n_na_period_2 <- clean_mun_df %>% 
  filter(is.na(Total)) %>%
  count(Periodo, sort = TRUE, name = "n_na")

total_period_2 <- clean_mun_df %>% 
  count(Periodo, sort = TRUE)


n_na_period_2$n_total <- total_period_2$n

n_na_period_2$perc <- n_na_period_2$n_na / total_period_2$n * 100
n_na_period_2$perc_total <- n_na_period_2$n_na / dim(clean_mun_df)[1] * 100



print(head(n_na_period_2, 8))

```


Se observaron patrones interesantes en la variable *Periodo*. En ambos conjuntos de datos, el año 2023 presentaba la mayor proporción de valores faltantes. Sin embargo, en el dataset municipal, se identificó entre 2010 y 2013 un bajo porcentaje de datos faltantes (13.77%), siendo igual en los tres años. No obstante, el porcentaje total de datos faltantes para todos los años es relativamente bajo, inferior al 2%. Por lo tanto, se decidió imputar estos valores para completar el conjunto de datos.



```{r include=FALSE}
clean_mun_df %>%
  filter(is.na(Total)) %>%
  count(Municipios, sort = TRUE) %>%
  ggplot(aes(x = reorder(Municipios, n), y = n)) +
    geom_bar(stat = "identity", fill = "skyblue") +
    coord_flip() +  # Voltea el gráfico para que los indicadores estén en el eje y
    labs(
      title = "NAs por año del dataset por municipios",
      x = "Periodo",
      y = "Cantidad de NA"
    ) +
    theme_minimal()
```


```{r include=FALSE}
n_na_mun <- clean_mun_df %>% 
  filter(is.na(Total)) %>%
  count(Municipios, sort = TRUE, name = "n_na")

total_period_2 <- clean_mun_df %>% 
  count(Municipios, sort = TRUE)


n_na_mun$n_total <- total_period_2$n

n_na_mun$perc <- n_na_mun$n_na / total_period_2$n * 100
n_na_mun$perc_total <- n_na_mun$n_na / dim(clean_mun_df)[1] * 100
n_na_mun
```



En el caso de la variable *Municipios*, se puede destacar que se identificaron 17 municipios con un porcentaje considerable de valores faltantes, específicamente del 37.14%. Dado que este porcentaje no supera el 50%, se decidió imputar estos valores en lugar de prescindir de dichos municipios.	

Finalmente, se observó una mejora de valores faltantes al prescindir de la variable *Sexo* y de los indicadores con mayor proporción de *NAs*:




```{r}
df1 <- clean_total_df %>% select(-Ind)
df2 <- clean_mun_df %>% select(-Ind)



p_total <- round(colSums(is.na(df1)) / dim(df1)[1] *100, 2)
p_mun <- round(colSums(is.na(df2)) / dim(df2)[1] *100, 2)
```


```{r}
kable(p_total, caption = "Porcentajes de NAs conjunto Total Nacional\\label{total_na_post}")
```


```{r}
kable(p_mun, caption = "Porcentajes de NAs por municipios\\label{mun_na_post}")
```



Destacar también que se estudió la existencia de observaciones duplicadas, obteniendo ausencia de estas.


#### Imputación



```{r}
# Imputacion del dataset Total Nacional

# Ajustar las opciones para mostrar números en notación decimal
options(scipen = 999)


medianas_total <- clean_total_df %>%
  group_by(Indicadores) %>%
  summarise(mediana_total = median(Total, na.rm = TRUE))

medias_total <- clean_total_df %>%
  group_by(Indicadores) %>%
  summarise(media_total = mean(Total, na.rm = TRUE))

diff_total <- abs(medianas_total[,2] - medias_total[,2])

# Como en ciertos indicadores difiere mucho la mediana de la media se imputa con la mediana

```

```{r}
total_data <- clean_total_df %>%
  left_join(medianas_total, by = "Indicadores") %>%
  mutate(Total = ifelse(is.na(Total), mediana_total, Total)) %>%
  select(-mediana_total)  # Eliminar la columna de medianas después de la imputación

```





```{r include=FALSE}
#libreria naniar
mcar_test(clean_mun_df)
```



```{r include=FALSE}
#Parecen datos faltantes de tipo MAR (Missing At Random, es decir, dependen de variables observadas)


# MICE trabaja con datos en formato wide

wide_data <- clean_mun_df %>% select(-Indicadores) %>%
  pivot_wider(
    names_from = Ind,
    values_from = Total
  )

# # Imputar los valores faltantes utilizando mice
# # imputed_data <- mice(wide_data %>% select(where(is.numeric)), method = 'rf', m = 5, maxit = 25, seed = 500)
# imputed_data <- mice(wide_data %>% select(where(is.numeric)), method = 'cart', m = 5, maxit = 25, seed = 500)
# 
# mice_mun_data <- complete(imputed_data)
# 
# # Guardamos como RData el dataframe mice_mun_data, para cargarlo en lugar de ejecutar la importación cada vez
# saveRDS(mice_mun_data, file = "./data/mice_mun_data.rds" )
mice_mun_data <- readRDS("./data/mice_mun_data.rds")

# Combinar los datos imputados con las columnas originales (Municipios y Periodo)
wide_data_imputed <- wide_data
wide_data_imputed[ , names(mice_mun_data)] <- mice_mun_data

# Para algunos municipios e indicadores, los valores faltantes (NA) están al principio de la serie temporal, sin datos previos disponibles. Por lo tanto, necesitamos imputarlos de forma separada, utilizando extrapolación lineal

wide_data_imputed <- wide_data_imputed %>%
  group_by(Municipios) %>%
  mutate(Nac_Ext_Total = zoo::na.approx(Nac_Ext_Total, x = Periodo, rule = 2, na.rm = FALSE))

wide_data_imputed <- wide_data_imputed %>%
  group_by(Municipios) %>%
  mutate(Ext_Total = zoo::na.approx(Ext_Total, x = Periodo, rule = 2, na.rm = FALSE))

wide_data_imputed <- wide_data_imputed %>%
  group_by(Municipios) %>%
  mutate(Ocup_20_64 = zoo::na.approx(Ocup_20_64, x = Periodo, rule = 2, na.rm = FALSE))


# Volvemos al formato tidy
mun_data <- wide_data_imputed %>%
  pivot_longer(
    cols = -c(Municipios, Periodo),
    names_to = "Ind",
    values_to = "Total"
  )
```


Para la imputación, en primera instancia se optó por imputar ambos datasets mediante una medida de tendencia central, dependiendo del indicador al que estaba asociada cada observación. Tras la imputación, en el caso del conjunto por municipios, se observó que esta imputación sesgaba los datos y se decidió usar una técnica más sofisticada.

Como en el análisis parecían existir ciertos patrones de los faltantes con las variables del conjunto de datos, se realizó el test de Little's MCAR, rechazando así la hipótesis nula de que los datos faltantes eran completamente al azar (Missing Completely At Random). Esto confirmó nuestra hipótesis de que podrían depender de las variables observadas (Missing At Random). Tras estos resultados, se empleó la función *mice* con el método 'cart' (Classification and Regression Trees). Este método crea árboles de decisión para predecir los valores faltantes basándose en las relaciones entre las variables observadas. No obstante, tras esta imputación, para algunos municipios e indicadores, los valores faltantes estaban al principio de la serie temporal, sin datos previos disponibles. Por tanto, se imputaron de forma separada, utilizando extrapolación lineal.

Para el dataset por municipios se calcularon tanto la media como la mediana de Total para cada grupo de *Indicadores*. Luego, se compararon estas dos medidas y se observó que, en ciertos indicadores, la diferencia entre la media y la mediana era significativa. Debido a estas discrepancias, se decidió utilizar la mediana para la imputación, ya que es menos sensible a los valores atípicos.



## Análisis Univariante

```{r}
# mun_univ DATAFRAME TOTAL NACIONAL LIMPIO
mun_univ <- mun_data %>% rename(Indicadores = Ind) %>% relocate(Indicadores, .before = Periodo)

# total_univ DATAFRAME TOTAL NACIONAL LIMPIO
total_univ <- total_data %>% select(-Indicadores) %>% rename(Indicadores = Ind) %>% relocate(Indicadores, .before = Periodo)

```

### Características generales

En esta sección se lleva a cabo un análisis preeliminar de los dos datasets que van a ser estudiados, prestando especial atención a las posibles anomalías, como datos inconsistentes u outliers.

Se estudian paralelamente los dos dataframes: uno de ellos contiene los valores de los indicadores para cada municipio (`r nrow(mun_univ)` observaciones), y el otro  los valores del total nacional (`r nrow(total_univ)` observaciones). En la Tabla \ref{tabla:codebook} podemos ver las variables y su tipo.

```{r codebook}
codebook <- data.frame(
  Variable = colnames(mun_univ),
  Tipo = c("Texto","Texto","Fecha","Numérica"),
  Niveles = c(
    length(unique(c(total_univ$Municipios, mun_univ$Municipios))),
    length(unique(c(total_univ$Indicadores, mun_univ$Indicadores))),
    length(unique(c(total_univ$Periodo, mun_univ$Periodo))),
    "N/A"),
  Valores = c(
    paste(c(head(unique(c(as.character(total_univ$Municipios), as.character(mun_univ$Municipios))), 2),
          "...",
          tail(unique(c(as.character(total_univ$Municipios), as.character(mun_univ$Municipios))), 1)), 
          collapse = ", "),
    paste(c(head(unique(c(as.character(total_univ$Indicadores), as.character(mun_univ$Indicadores))), 1),
          "...",
          tail(unique(c(as.character(total_univ$Indicadores), as.character(mun_univ$Indicadores))), 1)), 
          collapse = ", "),
    paste(range(c(mun_univ$Periodo, total_univ$Periodo)), collapse = " - "),
    paste(range(c(mun_univ$Total, total_univ$Total)), collapse = " - "))
  )


    
kable(codebook, caption = "Variables de ambos datasets\\label{tabla:codebook}")
     
```

* Municipios: Municipio del que se han obtenido los datos.
* Indicadores: Estadístico demográfico, económico o social que se está calculando.
* Periodo: Año al que hace referencia el indicador estadístico.
* Total:Valor numérico asociado al indicador estadístico, que puede ser un valor absoluto, una tasa o un porcentaje.
    
Sin embargo, para nuestro análisis es relevante considerar cada indicador como una variable individual, en lugar de mantenerlos agrupados en la columna *Indicadores*, optamos por transformar los datasets a formato wide, de manera que quede cada indicador como una variable nueva. 

```{r}
# Transformamos ambos datasets a formato wide
mun_wide <- pivot_wider(mun_univ, names_from="Indicadores", values_from="Total")
total_wide <- pivot_wider(total_univ, names_from="Indicadores", values_from="Total")

```

En el caso de las variables *Municipio* y *Periodo*, son consideradas como variables no númericas y se han revisado sus valores únicos y sus frecuencias absolutas y relativas, para asegurar que no hay ninguna anomalía.

```{r, include = FALSE}
# Obtenemos las frecuencias aboslutas de la variable Municipios
sort(table(mun_wide$Municipios))

# Obtenemos las frecuencias aboslutas de la variable Municipios, en ambos dfs
sort(table(mun_wide$Periodo))
sort(table(total_wide$Periodo))

# Al realizar este analisis después de la limpieza inicial de los datos y su imputación, vemos que todos los municipios y los periodos estan igualmente representados
```


Respecto a las variables numéricas, se revisan sus principales estadísticos descriptivos, para detectar posibles valores negativos, tasas o proporciones mayores que 100, etc... De nuevo no se detectan inconsistencias.

```{r include=FALSE}
# En el caso del dataset por municipios:
summary(mun_wide[-c(1,2)])

# En el caso del dataset de Total Nacional:
summary(mun_wide[-c(1,2)])

```

### Exploración visual

Para buscar valores anómalos se decide graficar los indicadores en boxplots (Figuras \ref{fig:boxplot1} y \ref{fig:boxplot2}). 

```{r boxplot1, fig.cap="Boxplot múltiple del dataset por municipios"}
# Escalar las variables numéricas restando la media y dividiendo entre la desviación estandar para poder comparar todos los indicadores en un solo grafico
# Convertir a formato largo para poder obtener el gráfico con ggplot2
mun_univ_transformed <- mun_wide %>%
  mutate(across(where(is.numeric), scale)) %>%
  pivot_longer(cols = where(is.numeric), 
               names_to = "Indicadores", 
               values_to = "Total")

ggplot(mun_univ_transformed, aes(x = Indicadores, y = Total)) +
  geom_boxplot(fill = "skyblue", color = "black") + 
  theme_minimal() +
  labs(
    title = "Boxplot de los Indicadores por municipios",
    x = "Indicador",
    y = "Total"
  ) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),  # Rotar las etiquetas del eje x
    plot.title = element_text(hjust = 0.5)  # Centrar el título
  )
```

```{r boxplot2, fig.cap="Boxplot múltiple del dataset total nacional"}
# Convertir a formato largo para poder obtener el gráfico con ggplot2
total_univ_transformed <- total_wide %>%
  mutate(across(where(is.numeric), scale)) %>%
  pivot_longer(cols = where(is.numeric), 
               names_to = "Indicadores", 
               values_to = "Total")

ggplot(total_univ_transformed, aes(x = Indicadores, y = Total)) +
  geom_boxplot(fill = "skyblue", color = "black") + 
  theme_minimal() +
  labs(
    title = "Boxplot de los Indicadores de Total Nacional",
    x = "Indicador",
    y = "Total"
  ) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),  # Rotar las etiquetas del eje x
    plot.title = element_text(hjust = 0.5)  # Centrar el título
  )
```

Se decide estudiar individualmente aquellos indicadores que visualmente parecen susceptibles de presentar datos anómalos:

* De los datos por municipios, ninguno de los indicadores parece presentar valores anómalos.

* De los datos del Total Nacional: *Esperanza de Vida*, *Número de Hogares*,, *Proporción de Población entre 0 y 14 años*, *Proporción de Empleos en Industria*, *Proporción de Empleo en Servicios y Tasa de Mortalidad*.

```{r}
# Seleccionamos los indicadores que tenemos que revisar
revisar_total <- abrev <- c("Pob_0_14", 
               "Esp_Vida", "Tasa_Mortalidad", "Emp_Servicios",
               "Emp_Industria")

boxplots_mun = list()

# Realizamos boxplots interactivos con puntos (jitter)
for (r in revisar_total){
  # Grafico con ggplot
  ggplot_box <- 
    ggplot(total_wide, aes(x = "1", y = total_wide[[r]])) +
    geom_boxplot( fill = "skyblue", alpha = 0.5) +
    geom_jitter( aes( text = paste("Periodo:", Periodo,"<br>Total", total_wide[[r]]  )), width = 0.2, height = 0, shape = 21, color = "black", fill = "skyblue", alpha = 0.7) +
    theme_minimal() +
    labs( y = " ", x = r ) +
    theme( axis.title.x = element_text(face = "bold"), axis.text.x = element_blank(), axis.ticks.x = element_blank() )
  
  # Convertir el gráfico a interactivo
  interactive_plot <- plotly::ggplotly(ggplot_box, tooltip = "text")
  
  # Guardar el gráfico en una lista
  boxplots_mun <- append(boxplots_mun, list(interactive_plot))
  # Estos graficos interactivos no se pueden incluir en pdf, pero podemos consultarlos en HTML o directamente en RStudio
}


```

En el caso del dataset del Total Nacional:

  +  En la variable *Esperanza de Vida* vemos que hay valores que superan los "límites" superior e inferior, a pesar de que siguen siendo muy similares al resto. Esto se debe a que esta variable presenta muy poca variabilidad (la desviación típica de esta variable es `r sd(total_wide$Esp_Vida)`). Por lo tanto tampoco se consideran valores anómalos. 
  
  +  En las variables *Proporción de Empleo en Servicios* y *Proporción de Empleo en Industria*, observamos una situación similar a la anterior (variables con poca variabilidad: desviación típica pequeña y rango reducido). Además, los valores más "extremos" corresponden a los mismos años, pero se comportan de manera inversa entre sí. De nuevo, estos valores no se consideran anómalos.
  
```{r, include=FALSE}
prop_empleos <- data.frame(
  Variable = c("Emp_Industria", "Emp_Servicios"),
  SD = c(sd(total_wide$Emp_Industria), sd(total_wide$Emp_Servicios)),
  Mínimo = c(min(total_wide$Emp_Industria), min(total_wide$Emp_Servicios)),
  Máximo = c(max(total_wide$Emp_Industria), max(total_wide$Emp_Servicios))
)
kable(prop_empleos)

# df_prop_empleos <- total_wide[c("Periodo", "Prop_Empleo_Industria", "Prop_Empleo_Servicios")]
# 
# ggplot(df_prop_empleos)+
#   geom_line(aes(x = Periodo, y = Prop_Empleo_Industria, color = "skyblue"))+
#   geom_line(aes(x = Periodo, y = Prop_Empleo_Servicios, color = "darkred"))+
#   scale_y_continuous(limits = c(0, 100))
```

  
  +  En el caso de la variable *Proporción de población de  0-14 años*, el dato `r max(total_wide$Pob_0_14)` sí se considera un dato anómalo, ya que es un valor muy alto en comparación al resto (el resto de valores de la variable oscilan entre `r range(total_wide$Pob_0_14[-which.max(total_wide$Pob_0_14)])`%). Además, para cada observación, la suma de las variables *Prop_0_14*, *Prop_15_64* y *Prop_65* da un resultado muy cercano al 100%, pero para en el caso del dato anómalo la suma resulta en `r sum(total_wide[which.max(total_wide$Pob_0_14),4:6])`.
Se decide corregir este valor para que la suma de las tres proporciones sea 100.

```{r}
# Reemplazamos en el formato wide
i <- which.max(total_wide$Pob_0_14)
nuevo_valor <- 100 - total_wide$Pob_15_64[i] - total_wide$Pob_65mas[i]
total_wide$Pob_0_14[i] <- nuevo_valor 

# Reemplazamos en el formato long
total_univ <- total_univ %>%
  mutate( Total = ifelse(
      Indicadores == "Pob_0_14" & Total == max(Total[Indicadores == "Pob_0_14"], na.rm = TRUE),
      nuevo_valor,
      Total))

# Reemplazamos en el dataset original total_data, para que esté disponible para los siguientes análisis
total_data <- total_data %>%
  mutate( Total = ifelse(
      Ind == "Pob_0_14" & Total == max(Total[Ind == "Pob_0_14"], na.rm = TRUE),
      nuevo_valor,
      Total))



```

  + Finalmente revisamos el valor máximo de la variable *Tasa de Mortalidad*. Este valor corresponde al año 2020, por lo que dicho en la tasa de mortalidad podría estar relacionado con la pandemia de COVID-19. A pesar de que este dato podría tener un impacto significativo, no se considera un valor anómalo y se decide mantenerlo porque aporta información que puede ser de utilidad.
  
Como parte del análisis univariante, también se lleva a cabo un estudio sobre las distribuciones de los diferentes indicadores a lo largo del tiempo. Para este análisis, se utiliza exclusivamente el dataset de Total Nacional, para obtener una visión general de todo el país y se destacan algunos puntos interesantes:

* Indicadores demográficos (Tabla \ref{fig:tiempo} izquierda) : Los datos muestran claramente una tendencia al envejecimiento de la población. Esto se ve reflejado de forma direca en el aumento de la edad media, pero también en otros indicadores. A lo largo de los años, la proporción de población de 0 a 14 años disminuye de forma notable, mientras que aumentan las proporciones de población de 15 a 64 años y de más de 64 años. Esto se ve, reforzado por un descenso de la Tasa de Natalidad (con un pequeño repunte en los últimos años).

* Indicadores económicos (Tabla \ref{fig:tiempo} derecha) : En cuanto a los indicadores económicos, se destacan los relacionados con el empleo. Como era de esperar, la Tasa de Desempleo y la Tasa de Ocupados (de 20 a 64 años) siguen tendencias opuestas con el paso de los años. Durante el periodo analizado, se aprecia una fase de recesión laboral hasta 2013, y tras el final de la crisis de la burbuja inmobiliaria (2008-2014), mejoran las tasas de desempleo y de ocupación, aunque sufren un pequeño descenso en 2019.


```{r}
indicadores_dem <- c("Pob_0_14", "Pob_15_64", "Pob_65mas", "Tasa_Natalidad", "Tasa_Mortalidad", "Edad_Med")

total_univ_dem <- total_univ %>% filter(Indicadores %in% indicadores_dem)

grafico_dem <- ggplot(total_univ_dem, aes(x = Periodo, y = Total, color = Indicadores)) +
  geom_line(size = 1.2) +
  scale_x_date(date_breaks = "1 year", date_labels = "%Y") +
  scale_color_discrete(guide = guide_legend(keywidth = 0.5, keyheight = 0.5))+
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),  
    plot.title = element_text(hjust = 0.5),
    legend.position = "bottom",
    legend.text = element_text(size = 8)
  )+
  labs(
    title = "Indicadores demográficos",
    x = "Periodo",
    y = "Total",
    color = NULL
  )


indicadores_empleo <- c("Tasa_Desempleo", "Ocup_20_64","Tasa_Actividad")

total_univ_empleo <- total_univ %>% filter(Indicadores %in% indicadores_empleo)

grafico_empleo <- ggplot(total_univ_empleo, aes(x = Periodo, y = Total, color = Indicadores)) +
  geom_line(size = 1.2) +
  scale_x_date(date_breaks = "1 year", date_labels = "%Y") +
  scale_color_discrete(guide = guide_legend(keywidth = 0.5, keyheight = 0.5))+
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),  # Rotar las etiquetas del eje x
    plot.title = element_text(hjust = 0.5),
    legend.position = "bottom",
    legend.text = element_text(size = 8)
    
  )+
  labs(
    title = "Indicadores empleo",
    x = "Periodo",
    y = "Total",
    color = NULL
  )
  


```

```{r tiempo, out.width= "100%", fig.cap="Estudio de los Indicadores respecto al Periodo"}
grid.arrange(grafico_dem, grafico_empleo, ncol = 2)
```



### Estadísticos descriptivos

Una vez eliminado e imputado el dato anómalo encontrado, se vuelven a calcular los estadisticos descriptivos de las variables numéricas, es decir, de todos los indicadores de ambos datasets. Las tablas con los estadísticos descriptivos del dataset por municipios y del dataset total se muestran en las tablas \ref{tabla:anexo1_1} y \ref{tabla:anexo1_2} del Anexo 1.

```{r}
# En el caso del dataset por municipios:

numericas <- mun_wide %>% select(where(is.numeric))
numericas <- numericas[-1]

estadisticos <- data.frame(
  Indicador = character(),
  Min = numeric(),
  Q1 = numeric(),
  Media = numeric(),
  Mediana = numeric(),
  Q3 = numeric(),
  Max = numeric(),
  SD = numeric()
)

for (i in 1:ncol(numericas)) {
  
  indicador <- colnames(numericas)[i]
  estadisticos[i, "Indicador"] <- indicador
  estadisticos[i, "Min"] <- min(numericas[[indicador]], na.rm = TRUE)
  estadisticos[i, "Q1"] <- quantile(numericas[[indicador]], 0.25, na.rm = TRUE)
  estadisticos[i, "Media"] <- mean(numericas[[indicador]], na.rm = TRUE)
  estadisticos[i, "Mediana"] <- median(numericas[[indicador]], na.rm = TRUE)
  estadisticos[i, "Q3"] <- quantile(numericas[[indicador]], 0.75, na.rm = TRUE)
  estadisticos[i, "Max"] <- max(numericas[[indicador]], na.rm = TRUE)
  estadisticos[i, "SD"] <- sd(numericas[[indicador]], na.rm = TRUE)
}

anexo1_1 <- kable(estadisticos, 
             digits = 2, 
             caption = "Estadísticos Dataset por Municipios\\label{tabla:anexo1_1}")


# En el caso del dataset de Total Nacional:

numericas <- total_wide %>% select(where(is.numeric))

estadisticos <- data.frame(
  Indicador = character(),
  Min = numeric(),
  Q1 = numeric(),
  Media = numeric(),
  Mediana = numeric(),
  Q3 = numeric(),
  Max = numeric(),
  SD = numeric()
)

for (i in 1:ncol(numericas)) {
  
  indicador <- colnames(numericas)[i]
  estadisticos[i, "Indicador"] <- indicador
  estadisticos[i, "Min"] <- min(numericas[[indicador]], na.rm = TRUE)
  estadisticos[i, "Q1"] <- quantile(numericas[[indicador]], 0.25, na.rm = TRUE)
  estadisticos[i, "Media"] <- mean(numericas[[indicador]], na.rm = TRUE)
  estadisticos[i, "Mediana"] <- median(numericas[[indicador]], na.rm = TRUE)
  estadisticos[i, "Q3"] <- quantile(numericas[[indicador]], 0.75, na.rm = TRUE)
  estadisticos[i, "Max"] <- max(numericas[[indicador]], na.rm = TRUE)
  estadisticos[i, "SD"] <- sd(numericas[[indicador]], na.rm = TRUE)
}

anexo1_2 <- kable(estadisticos, 
             digits = 2, 
             caption = "Estadísticos Dataset Total Nacional\\label{tabla:anexo1_2}")

```

## Análisis bivariante

En este apartado se estudian las relaciones entre pares de variables para cada uno de los conjuntos de datos disponibles (por municipio y Total Nacional).

### Datos por municipio

En este caso, se obtiene la matriz de correlaciones para proceder al estudio, puesto que nos encontramos con variables de tipo numérico.


```{r matriz_correlaciones_municipios, fig.width=20, fig.height=10, fig.cap="\\label{fig:matriz_correlaciones_municipios}Matrices de correlación para los datos por municipios.", echo=FALSE}

# , fig.width=4.5, fig.height=2.5, fig.align='left', fig.cap="\\label{fig:estaciones_activas}"

# mun_data  DATAFRAME POR MUNICIPIOS LIMPIO
# Pivotamos a formato ancho para simplificar el analisis
wide_mun_data <- mun_data %>% pivot_wider(names_from=Ind, values_from=Total)
wide_mun_data$Periodo <- as.factor(format(wide_mun_data$Periodo, "%Y"))

## Calculamos la matriz de correlacion
# Seleccionamos solo las columnas numericas
numeric_data <- wide_mun_data[, sapply(wide_mun_data, is.numeric)]

# Calcular matriz de correlación
cor_matrix <- cor(numeric_data)
cor_matrix_spearman <- cor(numeric_data, method = "spearman")

## Visualización con corrplot
par(mfrow = c(1,2), mar = c(0.5, 0.5, 5, 0.5), oma = c(0, 2, 0, 2))  # Márgenes pequeños
corrplot(cor_matrix,
         method = "color",
         type = "lower",
         tl.cex = 1.5,           # Tamaño de etiquetas
         cl.cex = 1.5,             # Tamaño barra de colores
         addgrid.col = NA,       # Sin líneas de rejilla
         tl.col = "black",
         mar = c(0, 0, 1, 0))    # Eliminar márgenes adicionales
title("(a) Matriz de correlaciones usando Pearson", cex.main = 2)

corrplot(cor_matrix_spearman,
         method = "color",
         type = "lower",
         tl.cex = 1.5,           # Tamaño de etiquetas
         cl.cex = 1.5,             # Tamaño barra de colores
         addgrid.col = NA,       # Sin líneas de rejilla
         tl.col = "black",
         mar = c(0, 0, 1, 0))    # Eliminar márgenes adicionales
title("(b) Matriz de correlaciones usando Spearman", cex.main = 2)

# # Generar gráficos de dispersión para todos los pares
# ggpairs(numeric_data,
#         title = "Diagramas de dispersión y correlación entre indicadores",
#         progress = TRUE)
# 
# ggpairs_plot <- ggpairs(numeric_data, progress = TRUE)
# ggsave("scatterplot_matrix.png", plot = ggpairs_plot, width = 50, height = 50, limitsize = F)

# Convertir matriz de correlación a formato largo
cor_long <- as.data.frame(as.table(cor_matrix))

# Filtrar correlaciones significativas (|r| > 0.6)
high_corr <- cor_long[abs(cor_long$Freq) > 0.6 & cor_long$Var1 != cor_long$Var2, ]

# Eliminar duplicados manteniendo solo una de las combinaciones
high_corr <- high_corr[!duplicated(t(apply(high_corr[, c("Var1", "Var2")], 1, sort))), ]

# Ordenar por magnitud de la correlación
high_corr <- high_corr[order(-abs(high_corr$Freq)), ]

# Convertir matriz de correlación a formato largo
cor_long_spearman <- as.data.frame(as.table(cor_matrix_spearman))

# Filtrar correlaciones significativas (|r| > 0.6)
high_corr_spearman <- cor_long_spearman[abs(cor_long_spearman$Freq) > 0.6 & cor_long_spearman$Var1 != cor_long_spearman$Var2, ]

# Eliminar duplicados manteniendo solo una de las combinaciones
high_corr_spearman <- high_corr_spearman[!duplicated(t(apply(high_corr_spearman[, c("Var1", "Var2")], 1, sort))), ]

# Ordenar por magnitud de la correlación
high_corr_spearman <- high_corr_spearman[order(-abs(high_corr_spearman$Freq)), ]


# anti_join(high_corr, high_corr_spearman, by = c("Var1", "Var2"))
# inner_join(high_corr, high_corr_spearman, by = c("Var1", "Var2"))
```

En la figura \ref{fig:matriz_correlaciones_municipios} se pueden observar las matrices de correlaciones utilizando la correlación de Pearson y la correlación de Spearman, con el fin de observar tanto relaciones lineales como no lineales. Dado que no se aprecia una diferencia significativa entre las matrices, se puede inferir que las relaciones entre las variables son probablemente lineales o no lineales monótonas.

```{r diagramas_dispersion, fig.width=15, fig.height=15, fig.cap= "\\label{fig:diagramas_dispersion}Diagramas de dispersión para los datos por municipios.", message=FALSE}

# Crear diagramas de dispersión
corr1 <- ggplot(wide_mun_data, aes(x = Tasa_Actividad, y = Pob_15_64)) +
  geom_point(color = "cornflowerblue") +
  geom_smooth(method = "lm", se = FALSE, color = "black", formula = y ~ x) +  # Línea de tendencia lineal para cada año
  theme_minimal(base_size = 15) +
  labs(
    title = "(a) Tasa_Actividad vs. Pob_15_64",
    x = "Tasa_Actividad",
    y = "Pob_15_64",
    caption = paste("Coeficiente de correlación:", round(high_corr$Freq[high_corr$Var1 == "Tasa_Actividad" & high_corr$Var2 == "Pob_15_64"], 2))
) + theme(legend.position = "none")


corr2 <- ggplot(wide_mun_data, aes(x = Edad_Med, y = Pob_65mas)) +
  geom_point(color = "cornflowerblue") +
  geom_smooth(method = "lm", se = FALSE, color = "black", formula = y ~ x) +  # Línea de tendencia lineal para cada año
  theme_minimal(base_size = 15) +
  labs(
    title = "(b) Edad_Med vs. Pob_65mas",
    x = "Edad_Med",
    y = "Pob_65mas",
    caption = paste("Coeficiente de correlación:", round(high_corr$Freq[high_corr$Var1 == "Edad_Med" & high_corr$Var2 == "Pob_65mas"], 2))
) + theme(legend.position = "none")


corr3 <- ggplot(wide_mun_data, aes(x = Ocup_20_64, y = Tasa_Desempleo)) +
  geom_point(color = "cornflowerblue") +
  geom_smooth(method = "lm", se = FALSE, color = "black", formula = y ~ x) +  # Línea de tendencia lineal para cada año
  theme_minimal(base_size = 15) +
  labs(
    title = "(c) Ocup_20_64 vs. Tasa_Desempleo",
    x = "Ocup_20_64",
    y = "Tasa_Desempleo",
    caption = paste("Coeficiente de correlación:", round(high_corr$Freq[high_corr$Var1 == "Ocup_20_64" & high_corr$Var2 == "Tasa_Desempleo"], 2))
) + theme(legend.position = "none")


corr4 <- ggplot(wide_mun_data, aes(x = Tasa_Mortalidad, y = Tasa_Natalidad)) +
  geom_point(color = "cornflowerblue") +
  geom_smooth(method = "lm", se = FALSE, color = "black", formula = y ~ x) +  # Línea de tendencia lineal para cada año
  theme_minimal(base_size = 15) +
  labs(
    title = "(d) Tasa_Mortalidad vs. Tasa_Natalidad",
    x = "Tasa_Mortalidad",
    y = "Tasa_Natalidad",
    caption = paste("Coeficiente de correlación:", round(high_corr$Freq[high_corr$Var1 == "Tasa_Mortalidad" & high_corr$Var2 == "Tasa_Natalidad"], 2))
) + theme(legend.position = "none")


corr5 <- ggplot(wide_mun_data, aes(x = Tasa_Desempleo, y = Pob_15_64)) +
  geom_point(color = "cornflowerblue") +
  geom_smooth(method = "lm", se = FALSE, color = "black", formula = y ~ x) +  # Línea de tendencia lineal para cada año
  theme_minimal(base_size = 15) +
  labs(
    title = "(e) Tasa_Desempleo vs. Pob_15_64",
    x = "Tasa_Desempleo",
    y = "Pob_15_64",
    caption = paste("Coeficiente de correlación:", round(cor_long$Freq[cor_long$Var1 == "Tasa_Desempleo" & cor_long$Var2 == "Pob_15_64"], 2))
) + theme(legend.position = "none")


corr6 <- ggplot(wide_mun_data, aes(x = Tasa_Desempleo, y = Pob_Res)) +
  geom_point(color = "cornflowerblue") +
  geom_smooth(method = "lm", se = FALSE, color = "black", formula = y ~ x) +  # Línea de tendencia lineal para cada año
  theme_minimal(base_size = 15) +
  labs(
    title = "(f) Tasa_Desempleo vs. Pob_Res",
    x = "Tasa_Desempleo",
    y = "Pob_Res",
    caption = paste("Coeficiente de correlación:", round(cor_long$Freq[cor_long$Var1 == "Tasa_Desempleo" & cor_long$Var2 == "Pob_Res"], 2))
) + theme(legend.position = "none")


ggarrange(corr1, corr2, corr3, NULL,NULL,NULL, corr4, corr5, corr6, nrow = 3, ncol = 3, heights = c(1, 0.05, 1))
```

Mediante gráficos de dispersión se comprueban algunas de las relaciones fuertes de las variables presentes en el conjunto. En este caso se consideran como fuertes aquellas relaciones cuyo coeficiente de correlación sea mayor a 0.6 en valor absoluto.

Algunas correlaciones positivas fuertes que destacan pueden ser la relación entre el porcentaje de población en edades económicamente activas (*Pob_15_64*) y la tasa de actividad (*Tasa_Actividad*), en la figura \ref{fig:diagramas_dispersion}.a); o la relación entre el porcentaje de población mayor de 65 años (*Pob_65mas*) y la edad media (*Edad_Med*) en la figura \ref{fig:diagramas_dispersion}.b, lo que puede reflejar una relación directa entre envejecimiento de la población y la proporción de adultos mayores de 65 años.

Por contra, también se observan correlaciones negativas fuertes como, por ejemplo, la relación entre la proporción de ocupados entre 20-64 años (*Ocup_20_64*) y la tasa de desempleo (*Tasa_Desempleo*) en la figura \ref{fig:diagramas_dispersion}.c, que refleja las dinámicas entre empleo y desempleo dentro del mercado laboral; o la relación entre la tasa de mortalidad (*Tasa_Mortalidad*) y la tasa de natalidad (*Tasa_Natalidad*) en la figura \ref{fig:diagramas_dispersion}.d, que puede sugerir dinámicas demográficas compensatorias en la población.

Una observación interesante es que la tasa de desempleo (*Tasa_Desempleo*) no muestra correlaciones fuertes ($|corr| > 0.6$) con variables de población como la proporción de población en edades económicamente activas (*Pob_15_64*), en la figura \ref{fig:diagramas_dispersion}.e; o la población total (*Pob_Res*) en la figura \ref{fig:diagramas_dispersion}.f, lo que puede sugerir que el desempleo no está directamente influido por características demográficas en el contexto estudiado.

### Datos totales

Al igual que en el apartado anterior, se obtiene la matriz de correlaciones para proceder al estudio, puesto que nos encontramos con variables de tipo numérico.

```{r matriz_correlaciones_totales, fig.width=20, fig.height=10, fig.cap="\\label{fig:matriz_correlaciones_totales}Matrices de correlación para los datos totales.", echo=FALSE}
### total_data DATAFRAME TOTAL NACIONAL LIMPIO
# Pivotamos a formato ancho para simplificar el analisis
wide_total_data <- total_data %>% select(-Indicadores)
wide_total_data <- wide_total_data %>% pivot_wider(names_from=Ind, values_from=Total)
wide_total_data$Periodo <- as.factor(format(wide_total_data$Periodo, "%Y"))

## Calculamos la matriz de correlacion
# Seleccionamos solo las columnas numericas
numeric_data_total <- wide_total_data[, sapply(wide_total_data, is.numeric)]

# Calcular matriz de correlación
cor_matrix_total <- cor(numeric_data_total)
cor_matrix_total_spearman <- cor(numeric_data_total, method = "spearman")

## Visualización con corrplot
par(mfrow = c(1,2), mar = c(0.5, 0.5, 5, 0.5), oma = c(0, 2, 0, 2))  # Márgenes pequeños
corrplot(cor_matrix_total,
         method = "color",
         type = "lower",
         tl.cex = 1.5,           # Tamaño de etiquetas
         cl.cex = 1.5,             # Tamaño barra de colores
         addgrid.col = NA,       # Sin líneas de rejilla
         tl.col = "black",
         mar = c(0, 0, 1, 0))    # Eliminar márgenes adicionales
title("(a) Matriz de correlaciones usando Pearson", cex.main = 2)

corrplot(cor_matrix_total_spearman,
         method = "color",
         type = "lower",
         tl.cex = 1.5,           # Tamaño de etiquetas
         cl.cex = 1.5,             # Tamaño barra de colores
         addgrid.col = NA,       # Sin líneas de rejilla
         tl.col = "black",
         mar = c(0, 0, 1, 0))    # Eliminar márgenes adicionales
title("(b) Matriz de correlaciones usando Spearman", cex.main = 2)

# # Generar gráficos de dispersión para todos los pares
# ggpairs(numeric_data_total,
#         title = "Diagramas de dispersión y correlación entre indicadores",
#         progress = TRUE)
# 
# ggpairs_plot <- ggpairs(numeric_data_total, progress = TRUE)
# ggsave("scatterplot_matrix_total.png", plot = ggpairs_plot, width = 50, height = 50, limitsize = F)

# Convertir matriz de correlación a formato largo
cor_long_total <- as.data.frame(as.table(cor_matrix_total))

# Filtrar correlaciones significativas (|r| > 0.6)
high_corr_total <- cor_long_total[abs(cor_long_total$Freq) > 0.6 & cor_long_total$Var1 != cor_long_total$Var2, ]

# Eliminar duplicados manteniendo solo una de las combinaciones
high_corr_total <- high_corr_total[!duplicated(t(apply(high_corr_total[, c("Var1", "Var2")], 1, sort))), ]

# Ordenar por magnitud de la correlación
high_corr_total <- high_corr_total[order(-abs(high_corr_total$Freq)), ]

# Convertir matriz de correlación a formato largo
cor_long_total_spearman <- as.data.frame(as.table(cor_matrix_total_spearman))

# Filtrar correlaciones significativas (|r| > 0.6)
high_corr_total_spearman <- cor_long_total_spearman[abs(cor_long_total_spearman$Freq) > 0.6 & cor_long_total_spearman$Var1 != cor_long_total_spearman$Var2, ]

# Eliminar duplicados manteniendo solo una de las combinaciones
high_corr_total_spearman <- high_corr_total_spearman[!duplicated(t(apply(high_corr_total_spearman[, c("Var1", "Var2")], 1, sort))), ]

# Ordenar por magnitud de la correlación
high_corr_total_spearman <- high_corr_total_spearman[order(-abs(high_corr_total_spearman$Freq)), ]


# anti_join(high_corr_total, high_corr_total_spearman, by = c("Var1", "Var2"))
# inner_join(high_corr_total, high_corr_total_spearman, by = c("Var1", "Var2"))
```

En la figura \ref{fig:matriz_correlaciones_totales} se puede observar la matriz de correlaciones utilizando la correlación de Pearson y la correlación de Spearman, con el fin de observar tanto relaciones lineales como no lineales. En este caso, se identifican discrepancias entre ambas matrices, lo que podría sugerir la existencia de relaciones no lineales entre algunos de los indicadores.

```{r diagramas_dispersion_totales, fig.width=10, fig.height=10, fig.cap= "\\label{fig:diagramas_dispersion_totales}Diagramas de dispersión para los datos totales.", message=FALSE}
# Crear diagramas de dispersión
corr1 <- ggplot(wide_total_data, aes(x = Tasa_Actividad, y = Pob_15_64)) +
  geom_point(color = "cornflowerblue") +
  geom_smooth(method = "lm", se = FALSE, color = "black", formula = y ~ x) +  # Línea de tendencia lineal para cada año
  theme_minimal(base_size = 15) +
  labs(
    title = "(a) Tasa_Actividad vs. Pob_15_64",
    x = "Tasa_Actividad",
    y = "Pob_15_64",
    caption = paste("Coeficiente de correlación:", round(high_corr_total$Freq[high_corr_total$Var1 == "Tasa_Actividad" & high_corr_total$Var2 == "Pob_15_64"], 2))
) + theme(legend.position = "none")


corr2 <- ggplot(wide_total_data, aes(x = Tasa_Actividad, y = Tasa_Natalidad)) +
  geom_point(color = "cornflowerblue") +
  geom_smooth(method = "lm", se = FALSE, color = "black", formula = y ~ x) +  # Línea de tendencia lineal para cada año
  theme_minimal(base_size = 15) +
  labs(
    title = "(b) Tasa_Actividad vs. Tasa_Natalidad",
    x = "Tasa_Actividad",
    y = "Tasa_Natalidad",
    caption = paste("Coeficiente de correlación:", round(high_corr_total$Freq[high_corr_total$Var1 == "Tasa_Actividad" & high_corr_total$Var2 == "Tasa_Natalidad"], 2))
) + theme(legend.position = "none")


corr3 <- ggplot(wide_total_data, aes(x = Tasa_Actividad, y = Edad_Med)) +
  geom_point(color = "cornflowerblue") +
  geom_smooth(method = "lm", se = FALSE, color = "black", formula = y ~ x) +  # Línea de tendencia lineal para cada año
  theme_minimal(base_size = 15) +
  labs(
    title = "(c) Tasa_Actividad vs. Edad_Med",
    x = "Tasa_Actividad",
    y = "Edad_Med",
    caption = paste("Coeficiente de correlación:", round(high_corr_total$Freq[high_corr_total$Var1 == "Tasa_Actividad" & high_corr_total$Var2 == "Edad_Med"], 2))
) + theme(legend.position = "none")


corr4 <- ggplot(wide_total_data, aes(x = Hog_1P, y = Pob_15_64)) +
  geom_point(color = "cornflowerblue") +
  geom_smooth(method = "lm", se = FALSE, color = "black", formula = y ~ x) +  # Línea de tendencia lineal para cada año
  theme_minimal(base_size = 15) +
  labs(
    title = "(d) Hog_1P vs. Pob_15_64",
    x = "Hog_1P",
    y = "Pob_15_64",
    caption = paste("Coeficiente de correlación:", round(high_corr_total$Freq[high_corr_total$Var1 == "Hog_1P" & high_corr_total$Var2 == "Pob_15_64"], 2))
) + theme(legend.position = "none")

ggarrange(corr1, corr2, NULL,NULL, corr3, corr4, nrow = 3, ncol = 2, heights = c(1, 0.05, 1))
```

Mediante gráficos de dispersión se comprueban algunas de las relaciones fuertes de las variables presentes en el conjunto. En este caso se consideran como fuertes aquellas relaciones cuyo coeficiente de correlación sea mayor a 0.6 en valor absoluto.

Algunas correlaciones positivas fuertes que destacan pueden ser la relación entre la proporción de población en edades económicamente activas (*Pob_15_64*) y la tasa de actividad (*Tasa_Actividad*), en la figura \ref{fig:diagramas_dispersion_totales}.a, lo que refleja que la actividad laboral es impulsada por personas en edad de trabajar; o la relación entre la tasa de natalidad (*Tasa_Natalidad*) y la tasa de actividad (*Tasa_Actividad*) en la figura \ref{fig:diagramas_dispersion_totales}.b, lo que puede reflejar la existencia de políticas de apoyo a la natalidad en el ámbito laboral. Podría reflejar también que la mejora de las condiciones de vida facilita la formación de una familia.

Por contra, también se observan correlaciones negativas fuertes como, por ejemplo, la relación entre la tasa de actividad (*Tasa_Actividad*) y la edad media de la población (*Edad_Med*) en la figura \ref{fig:diagramas_dispersion_totales}.c. Esta relación refleja que, a medida que la población envejece, aumenta la proporción de personas fuera del mercado laboral, lo que reduce la tasa de actividad. Además, una mayor edad media puede reflejar una menor incorporación de jóvenes al mercado laboral; Otra correlación negativa fuerte es la relación entre la proporción de hogares unipersonales (*Hog_1P*) y la proporción de población en edades económicamente activas (*Pob_15_64*) en la figura \ref{fig:diagramas_dispersion_totales}.d. Esta relación puede sugerir que, a medida que disminuye la población activa, aumenta la proporción de personas mayores que viven solas, lo que refleja el envejecimiento poblacional y los cambios en la estructura familiar, donde las personas mayores tienden a vivir solas.

# Anexo 1 {#Anexo}

```{r anexo1_1, fig.pos='H'}
anexo1_1
```

```{r anexo1_2, fig.pos='H'}
anexo1_2
```